import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
import os  # ì¶”ê°€: NameError í•´ê²°
import geopandas as gpd
import requests
from io import BytesIO
from folium.plugins import MarkerCluster
import numpy as np

st.set_page_config(page_title="ì´ìƒë™ê¸° ë²”ì£„ ê²½ë³´ ë§µ", page_icon="ğŸš¨", layout="wide", initial_sidebar_state="expanded")

@st.cache_data
def load_data(crime_path, indicator_path, prediction_path):
    # ìµœì í™”: í•„ìš”í•œ ì—´ë§Œ ë¡œë“œ, ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ê°„ì†Œí™”
    if not os.path.exists(crime_path):
        st.error("ë²”ì£„ ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        st.stop()
    df_crime = pd.read_csv(crime_path, encoding='cp949', usecols=['ë‚ ì§œ', 'ìœ„ë„', 'ê²½ë„'])
    df_crime['date'] = pd.to_datetime(df_crime['ë‚ ì§œ'], errors='co obiekcji')
    df_crime['ìœ„ë„'] = pd.to_numeric(df_crime['ìœ„ë„'], errors='coerce')
    df_crime['ê²½ë„'] = pd.to_numeric(df_crime['ê²½ë„'], errors='coerce')
    df_crime = df_crime.dropna(subset=['date', 'ìœ„ë„', 'ê²½ë„'])
    if 'full_address' not in df_crime.columns:
        df_crime['full_address'] = df_crime[['ìœ„ë„', 'ê²½ë„']].apply(lambda x: f"ìœ„ë„: {x['ìœ„ë„']}, ê²½ë„: {x['ê²½ë„']}", axis=1)
    crime_dates = sorted(df_crime['date'].dt.normalize().unique())
    
    if not os.path.exists(indicator_path):
        st.error("ì§€í‘œ ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        st.stop()
    df_indicator = pd.read_csv(indicator_path, encoding='cp949')
    df_indicator['date'] = pd.to_datetime(df_indicator['date'], errors='coerce')
    df_indicator = df_indicator[df_indicator['date'].dt.year <= 2023].dropna(subset=['date'])
    indicator_dates = sorted(df_indicator['date'].dt.normalize().unique())
    
    if not os.path.exists(prediction_path):
        st.error("ì˜ˆì¸¡ ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        st.stop()
    df_prediction = pd.read_csv(prediction_path, encoding='cp949', usecols=['date', 'ë„ë‹¨ìœ„', 'crime_probability'])
    df_prediction['date'] = pd.to_datetime(df_prediction['date'], errors='coerce')
    df_prediction = df_prediction.dropna(subset=['date', 'ë„ë‹¨ìœ„', 'crime_probability'])
    prediction_dates = sorted(df_prediction['date'].dt.normalize().unique())
    
    return df_crime, crime_dates, df_indicator, indicator_dates, df_prediction, prediction_dates

@st.cache_data(hash_funcs={gpd.GeoDataFrame: lambda x: str(x)})
def load_geojson():
    # ìµœì í™”: GeoJSONì„ ë¡œì»¬ íŒŒì¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ URL ìºì‹±
    geojson_url = "https://raw.githubusercontent.com/southkorea/southkorea-maps/master/gadm/json/skorea-provinces-geo.json"
    response = requests.get(geojson_url, timeout=5)
    geo_data = gpd.read_file(BytesIO(response.content))
    return geo_data

def calculate_risk_score(row, region):
    score = 0
    if f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}" in row and pd.notna(row[f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}"]) and row[f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}"] > 13:
        score += 1
    if f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}" in row and pd.notna(row[f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}"]) and row[f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}"] >= 0.7:
        score += 1
    if 'ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤' in row and pd.notna(row['ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤']) and row['ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤'] >= 2:
        score += 1
    return min(score, 3)

@st.cache_data
def create_risk_score_table(indicator_data, view_type, selected_year=None, selected_date=None):
    regions = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„', 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 
               'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ì „ë¼ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì œì£¼ë„', 
               'ì¶©ì²­ë‚¨ë„', 'ì¶©ì²­ë¶ë„']
    
    # ìµœì í™”: ë²¡í„°í™”ë¡œ ê³„ì‚° ì†ë„ ê°œì„ 
    def compute_scores(data, region):
        climate_col = f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}"
        social_col = f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}"
        climate_score = (data[climate_col].notna() & (data[climate_col] > 13)).astype(float).mean() if climate_col in data else 0
        social_score = (data[social_col].notna() & (data[social_col] >= 0.7)).astype(float).mean() if social_col in data else 0
        financial_score = (data['ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤'].notna() & (data['ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤'] >= 2)).astype(float).mean() if 'ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤' in data else 0
        return climate_score, social_score, financial_score
    
    table_data = []
    for region in regions:
        region_data = indicator_data
        if view_type == "ë…„ë„ë³„":
            region_data = region_data[region_data['date'].dt.year == selected_year]
        elif view_type == "ì¼ë³„":
            region_data = region_data[region_data['date'].dt.normalize() == selected_date.normalize()]
        
        if region_data.empty:
            table_data.append({
                'ì§€ì—­': region,
                'ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': 0,
                'ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': 0,
                'ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': 0,
                'ì´ ì ìˆ˜': 0
            })
            continue
        
        if view_type in ["ì „ì²´ ë°ì´í„°", "ë…„ë„ë³„"]:
            climate_score, social_score, financial_score = compute_scores(region_data, region)
        else:  # ì¼ë³„
            row = region_data.iloc[0]
            climate_score = 1 if pd.notna(row.get(f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}")) and row[f"ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤:{region}"] > 13 else 0
            social_score = 1 if pd.notna(row.get(f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}")) and row[f"ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤:{region}"] >= 0.7 else 0
            financial_score = 1 if pd.notna(row.get('ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤')) and row['ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤'] >= 2 else 0
        
        total_score = min(climate_score + social_score + financial_score, 3)
        table_data.append({
            'ì§€ì—­': region,
            'ê¸°í›„ìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': round(climate_score, 2),
            'ì‚¬íšŒìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': round(social_score, 2),
            'ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜': round(financial_score, 2),
            'ì´ ì ìˆ˜': round(total_score, 2)
        })
    
    return pd.DataFrame(table_data)

@st.cache_data
def create_prediction_table(prediction_data, selected_year=None, selected_date=None, prediction_mode="ë…„ë„ë³„"):
    regions = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„', 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 
               'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ì „ë¼ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì œì£¼ë„', 
               'ì¶©ì²­ë‚¨ë„', 'ì¶©ì²­ë¶ë„']
    
    # ìµœì í™”: groupbyë¡œ ì§€ì—­ë³„ ê³„ì‚° ê°„ì†Œí™”
    table_data = []
    for region in regions:
        region_data = prediction_data[prediction_data['ë„ë‹¨ìœ„'] == region]
        if selected_year and prediction_mode == "ë…„ë„ë³„":
            region_data = region_data[region_data['date'].dt.year == selected_year]
        elif selected_date and prediction_mode == "ì¼ë³„":
            region_data = region_data[region_data['date'].dt.normalize() == selected_date.normalize()]
        
        if region_data.empty:
            table_data.append({'ì§€ì—­': region, 'ìœ„í—˜ë¥ ': 'ë°ì´í„° ì—†ìŒ'})
            continue
        
        prob = region_data['crime_probability'].mean() if prediction_mode == "ë…„ë„ë³„" else region_data['crime_probability'].iloc[0]
        table_data.append({'ì§€ì—­': region, 'ìœ„í—˜ë¥ ': f"{prob:.3f}" if pd.notna(prob) else 'ë°ì´í„° ì—†ìŒ'})
    
    return pd.DataFrame(table_data)

def get_prediction_color(prob):
    if prob is None:
        return 'gray'
    return 'green' if prob < 0.3 else 'lime' if prob < 0.5 else 'yellow' if prob < 0.7 else 'orange' if prob < 0.85 else 'red'

def create_map(view_type, selected_year=None, selected_date=None, df_crime=None, df_indicator=None, df_prediction=None, geo_data=None):
    # ìµœì í™”: ì´ˆê¸° ì¤Œ ë ˆë²¨ ë‚®ì¶”ê³ , ë§ˆì»¤ ìˆ˜ ì œí•œ ê°•í™”
    m = folium.Map(location=[36.5, 127.5], zoom_start=6, tiles='CartoDB Positron')
    crime_group = folium.FeatureGroup(name="ë²”ì£„ ë§ˆì»¤", show=(view_type != "ì˜ˆì¸¡"))
    risk_group = folium.FeatureGroup(name="ìœ„í—˜ ì½”ë¡œí”Œë ›", show=True)
    marker_cluster = MarkerCluster(maxClusterRadius=30).add_to(crime_group)
    
    if view_type == "ì „ì²´ ë°ì´í„°":
        crime_data = df_crime
        indicator_data = df_indicator
        title = "ì „ì²´ ë°ì´í„° ë§µ"
    elif view_type == "ë…„ë„ë³„":
        crime_data = df_crime[df_crime['date'].dt.year == selected_year]
        indicator_data = df_indicator[df_indicator['date'].dt.year == selected_year]
        title = f"{selected_year}ë…„ ë§µ"
    elif view_type == "ì¼ë³„":
        selected_date_only = selected_date.normalize()
        crime_data = df_crime[df_crime['date'].dt.normalize() == selected_date_only]
        indicator_data = df_indicator[df_indicator['date'].dt.normalize() == selected_date_only]
        title = f"{selected_date_only.strftime('%Y-%m-%d')} ë§µ"
    else:  # ì˜ˆì¸¡ ëª¨ë“œ
        crime_data = pd.DataFrame()
        if selected_date:
            indicator_data = df_prediction[df_prediction['date'].dt.normalize() == selected_date.normalize()]
        else:
            indicator_data = df_prediction[df_prediction['date'].dt.year == selected_year]
        title = f"{selected_year}ë…„ ì˜ˆì¸¡ ë§µ" if selected_year else f"{selected_date.strftime('%Y-%m-%d')} ì˜ˆì¸¡ ë§µ"
    
    if view_type != "ì˜ˆì¸¡" and not crime_data.empty:
        # ìµœì í™”: ë§ˆì»¤ ìˆ˜ 1000ê°œë¡œ ì œí•œ
        crime_data_limited = crime_data.head(1000)
        point_count = len(crime_data)
        marker_color = 'green' if point_count < 100 else 'orange' if point_count < 500 else 'red'
        for _, row in crime_data_limited.iterrows():
            if pd.notna(row['ìœ„ë„']) and pd.notna(row['ê²½ë„']):
                folium.Marker(
                    location=[float(row['ìœ„ë„']), float(row['ê²½ë„'])],
                    icon=folium.Icon(color=marker_color, icon='exclamation-sign', prefix='glyphicon'),
                    popup=f"ë‚ ì§œ: {row['date'].strftime('%Y-%m-%d')}<br>ì§€ì—­: {row['full_address']}"
                ).add_to(marker_cluster)
        if point_count > 1000:
            st.info(f"ë²”ì£„ ë°ì´í„° {point_count}ê±´ ì¤‘ 1000ê±´ë§Œ í‘œì‹œ")
    
    regions = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„', 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 
               'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ì „ë¼ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì œì£¼ë„', 
               'ì¶©ì²­ë‚¨ë„', 'ì¶©ì²­ë¶ë„']
    region_mapping = {
        'Seoul': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'Gyeonggi-do': 'ê²½ê¸°ë„', 'Gangwon-do': 'ê°•ì›ë„', 'Gyeongsangnam-do': 'ê²½ìƒë‚¨ë„', 
        'Gyeongsangbuk-do': 'ê²½ìƒë¶ë„', 'Gwangju': 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'Daegu': 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'Daejeon': 'ëŒ€ì „ê´‘ì—­ì‹œ', 
        'Busan': 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'Sejong': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'Ulsan': 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'Incheon': 'ì¸ì²œê´‘ì—­ì‹œ', 
        'Jeollanam-do': 'ì „ë¼ë‚¨ë„', 'Jeollabuk-do': 'ì „ë¼ë¶ë„', 'Jeju': 'ì œì£¼ë„', 
        'Chungcheongnam-do': 'ì¶©ì²­ë‚¨ë„', 'Chungcheongbuk-do': 'ì¶©ì²­ë¶ë„'
    }
    
    scores = {region: 0 for region in regions}
    probabilities = {region: None for region in regions}
    
    if not indicator_data.empty:
        if view_type == "ì˜ˆì¸¡":
            # ìµœì í™”: groupbyë¡œ í‰ê·  ê³„ì‚°
            for region in regions:
                region_data = indicator_data[indicator_data['ë„ë‹¨ìœ„'] == region]
                if not region_data.empty:
                    probabilities[region] = region_data['crime_probability'].iloc[0] if selected_date else region_data['crime_probability'].mean()
        else:
            for region in regions:
                if view_type in ["ì „ì²´ ë°ì´í„°", "ë…„ë„ë³„"] and not selected_date:
                    region_scores = indicator_data.apply(lambda row: calculate_risk_score(row, region), axis=1)
                    scores[region] = round(region_scores.mean()) if not region_scores.empty else 0
                elif indicator_data.shape[0] > 0:
                    scores[region] = calculate_risk_score(indicator_data.iloc[0], region)
    
    def style_function(feature):
        region = region_mapping.get(feature['properties']['NAME_1'], feature['properties']['NAME_1'])
        prob = probabilities.get(region, None)
        color = get_prediction_color(prob) if view_type == "ì˜ˆì¸¡" else {0: 'green', 1: 'yellow', 2: 'orange', 3: 'red'}.get(scores.get(region, 0), 'green')
        return {'fillColor': color, 'color': 'black', 'weight': 1, 'fillOpacity': 0.3}
    
    def tooltip_function(feature):
        region = region_mapping.get(feature['properties']['NAME_1'], feature['properties']['NAME_1'])
        if view_type == "ì˜ˆì¸¡":
            prob = probabilities.get(region, None)
            prob_str = f"{prob:.3f}" if prob is not None else 'ì—†ìŒ'
            return folium.GeoJsonTooltip(fields=['NAME_1'], aliases=['ì§€ì—­'], extra_html=f'<br>ìœ„í—˜ë¥ : {prob_str}')
        return folium.GeoJsonTooltip(fields=['NAME_1'], aliases=['ì§€ì—­'], extra_html=f'<br>ìœ„í—˜ ì ìˆ˜: {scores.get(region, 0)}')
    
    folium.GeoJson(geo_data, style_function=style_function, tooltip=tooltip_function).add_to(risk_group)
    crime_group.add_to(m)
    risk_group.add_to(m)
    folium.LayerControl().add_to(m)
    
    legend_html = '''
        <div style="position: fixed; bottom: 50px; right: 50px; z-index:9999; background-color:white; padding:10px; border:2px solid grey;">
            <p><strong>ë²”ë¡€%s</strong></p>
            <p><strong>ìœ„í—˜ ì½”ë¡œí”Œë ›</strong></p>
            %s
            <p><strong>ë²”ì£„ ë§ˆì»¤</strong>%s</p>
            <p><span style="color:green;">â– </span> ì†Œìˆ˜ (<100ê±´)</p>
            <p><span style="color:orange;">â– </span> ë³´í†µ (<500ê±´)</p>
            <p><span style="color:red;">â– </span> ë‹¤ìˆ˜ (â‰¥500ê±´)</p>
        </div>
    ''' % (
        ' (ì˜ˆì¸¡)' if view_type == "ì˜ˆì¸¡" else '',
        '''
        <p><span style="color:green;">â– </span> ì•ˆì „ (<0.3)</p>
        <p><span style="color:lime;">â– </span> ëŒ€ë¹„ (0.3~0.5)</p>
        <p><span style="color:yellow;">â– </span> ì£¼ì˜ (0.5~0.7)</p>
        <p><span style="color:orange;">â– </span> ê²½ë³´ (0.7~0.85)</p>
        <p><span style="color:red;">â– </span> ìœ„í—˜ (â‰¥0.85)</p>
        ''' if view_type == "ì˜ˆì¸¡" else '''
        <p><span style="color:green;">â– </span> 0ì : ì•ˆì „</p>
        <p><span style="color:yellow;">â– </span> 1ì : ì£¼ì˜</p>
        <p><span style="color:orange;">â– </span> 2ì : ê²½ê³ </p>
        <p><span style="color:red;">â– </span> 3ì : ìœ„í—˜</p>
        ''',
        ': í‘œì‹œë˜ì§€ ì•ŠìŒ' if view_type == "ì˜ˆì¸¡" else ''
    )
    m.get_root().html.add_child(folium.Element(legend_html))
    
    if not crime_data.empty:
        avg_lat = crime_data['ìœ„ë„'].mean()
        avg_lon = crime_data['ê²½ë„'].mean()
        if pd.notna(avg_lat) and pd.notna(avg_lon):
            m.location = [avg_lat, avg_lon]
            m.zoom_start = 8
    
    return m, title

st.title("ì´ìƒë™ê¸° ë²”ì£„ ê²½ë³´ ë§µ")

# ê²½ë¡œ: Streamlit ë°°í¬ìš©
crime_path = "./data/15~25ë…„ë„ ì´ìƒë™ê¸°(ë„ë‹¨ìœ„ì¶”ê°€)_with_coords_openai.csv"
indicator_path = "./data/ì§€í‘œë°ì´í„°(4ëŒ€ë²”ì£„ì¶”ê°€ê³„ì‚°).csv"
prediction_path = "./data/crime_predictions_2024_2025_binary_risk.csv"

df_crime, crime_dates, df_indicator, indicator_dates, df_prediction, prediction_dates = load_data(crime_path, indicator_path, prediction_path)
geo_data = load_geojson()

with st.sidebar:
    st.title('ğŸš¨ ëŒ€ì‹œë³´ë“œ')
    view_type = st.selectbox('ë³´ê¸° ìœ í˜•', ['ì „ì²´ ë°ì´í„°', 'ë…„ë„ë³„', 'ì¼ë³„', 'ì˜ˆì¸¡'])
    
    selected_year = None
    selected_date = None
    
    if view_type in ['ë…„ë„ë³„', 'ì¼ë³„']:
        crime_years = [y for y in sorted(df_crime['date'].dt.year.unique()) if y <= 2023]
        selected_year = st.selectbox('ë…„ë„', crime_years, index=len(crime_years)-1)
        if view_type == 'ì¼ë³„':
            filtered_dates = [date for date in crime_dates if date.year == selected_year]
            if filtered_dates:
                selected_date = st.selectbox('ë‚ ì§œ', filtered_dates, format_func=lambda x: x.strftime('%Y-%m-%d'))
                selected_date = pd.to_datetime(selected_date)
            else:
                st.warning(f"{selected_year}ë…„ ë°ì´í„° ì—†ìŒ")
                view_type = "ë…„ë„ë³„"
    elif view_type == 'ì˜ˆì¸¡':
        prediction_years = sorted(df_prediction['date'].dt.year.unique())
        selected_year = st.selectbox('ì˜ˆì¸¡ ë…„ë„', prediction_years, index=len(prediction_years)-1)
        prediction_mode = st.radio('ì˜ˆì¸¡ ëª¨ë“œ', ['ë…„ë„ë³„', 'ì¼ë³„'])
        if prediction_mode == 'ì¼ë³„':
            filtered_dates = [date for date in prediction_dates if date.year == selected_year]
            if filtered_dates:
                selected_date = st.selectbox('ì˜ˆì¸¡ ë‚ ì§œ', filtered_dates, format_func=lambda x: x.strftime('%Y-%m-%d'))
                selected_date = pd.to_datetime(selected_date)
            else:
                st.warning(f"{selected_year}ë…„ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
                prediction_mode = "ë…„ë„ë³„"

st.markdown("#### í†µí•© ë§µ")
with st.spinner("ë§µì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
    combined_map, combined_title = create_map(view_type, selected_year, selected_date, df_crime, df_indicator, df_prediction, geo_data)
    folium_static(combined_map, width=1000, height=600)

st.markdown("#### ì§€ì—­ë³„ ìœ„í—˜ ì ìˆ˜/ì˜ˆì¸¡ í™•ë¥ ")
if view_type != "ì˜ˆì¸¡":
    risk_table = create_risk_score_table(df_indicator, view_type, selected_year, selected_date)
    st.dataframe(risk_table, use_container_width=True)
else:
    prediction_table = create_prediction_table(df_prediction, selected_year, selected_date, prediction_mode)
    st.dataframe(prediction_table, use_container_width=True)

if view_type != "ì˜ˆì¸¡":
    crime_count = len(df_crime[df_crime['date'].dt.year <= 2023]) if view_type == "ì „ì²´ ë°ì´í„°" else len(df_crime[df_crime['date'].dt.year == selected_year]) if view_type == "ë…„ë„ë³„" else len(df_crime[df_crime['date'].dt.normalize() == selected_date.normalize()])
    st.write(f"ë²”ì£„ ê±´ìˆ˜: {crime_count}")
else:
    st.write("ì˜ˆì¸¡ ëª¨ë“œ: crime_probability ê¸°ë°˜ ì½”ë¡œí”Œë › ë° í‘œ í‘œì‹œ")

with st.expander('ëŒ€ì‹œë³´ë“œ ì„¤ëª…', expanded=False):
    st.write('''
        **í†µí•© ë§µ**: ë²”ì£„ ë§ˆì»¤ì™€ ì§€ì—­ë³„ ìœ„í—˜ë„ë¥¼ ì§€ë„ì— í‘œì‹œ. ìš°ì¸¡ ìƒë‹¨ì—ì„œ ë ˆì´ì–´ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        **ë²”ì£„ ë§ˆì»¤** (2015~2023ë…„, ì˜ˆì¸¡ ëª¨ë“œ ì œì™¸):
        - ì´ˆë¡: ì†Œìˆ˜ (<100ê±´)
        - ì£¼í™©: ë³´í†µ (<500ê±´)
        - ë¹¨ê°•: ë‹¤ìˆ˜ (â‰¥500ê±´)

        **ìœ„í—˜ ì½”ë¡œí”Œë ›**:
        - **2015~2023ë…„** (ì „ì²´ ë°ì´í„°, ë…„ë„ë³„, ì¼ë³„):
          - ìœ„í—˜ë„ëŠ” ê¸°í›„, ì‚¬íšŒ, ê¸ˆìœµ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€í‘œë¡œ ê³„ì‚° (ê° ì§€í‘œê°€ ê¸°ì¤€ ì´ˆê³¼ ì‹œ 1ì , ìµœëŒ€ 3ì ).
          - ìƒ‰ìƒ: ì´ˆë¡(0ì , ì•ˆì „), ë…¸ë‘(1ì , ì£¼ì˜), ì£¼í™©(2ì , ê²½ê³ ), ë¹¨ê°•(3ì , ìœ„í—˜).
        - **2024~2025ë…„** (ì˜ˆì¸¡ ëª¨ë“œ):
          - ìœ„í—˜ë¥ ë¡œ ìœ„í—˜ë„ í‘œì‹œ. íˆ´íŒì— í™•ë¥  ê°’ ì œê³µ.
          - ìƒ‰ìƒ: ì´ˆë¡(<0.3, ì•ˆì „), ì—°ë‘(0.3 ~ 0.5, ëŒ€ë¹„), ë…¸ë‘(0.5 ~ 0.7, ì£¼ì˜), ì£¼í™©(0.7 ~ 0.85, ê²½ë³´), ë¹¨ê°•(â‰¥0.85, ìœ„í—˜).

        **ì§€ì—­ë³„ í‘œ**:
        - **2015~2023ë…„**: ì§€ì—­ë³„ ê¸°í›„, ì‚¬íšŒ, ê¸ˆìœµ ì ìˆ˜ì™€ ì´ì  í‘œì‹œ.
        - **2024~2025ë…„**: ì§€ì—­ë³„ ìœ„í—˜ë¥  í‘œì‹œ (ë…„ë„ë³„: í‰ê· , ì¼ë³„: íŠ¹ì • ë‚ ì§œ).

        **ë³´ê¸° ìœ í˜•**:
        - ì „ì²´ ë°ì´í„°/ë…„ë„ë³„/ì¼ë³„: 2015~2023ë…„ ì‹¤ì œ ë°ì´í„°.
        - ì˜ˆì¸¡: 2024~2025ë…„ ë²”ì£„ í™•ë¥  (ë…„ë„ë³„: í‰ê· , ì¼ë³„: íŠ¹ì • ë‚ ì§œ).
    ''')